{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.image as mpimg \n",
    "from PIL import Image\n",
    "from random import randint\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from ignite.metrics import DiceCoefficient, ConfusionMatrix\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataloader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "class DataTrain(Dataset):\n",
    "\n",
    "    def __init__(self, data, annotation):\n",
    "        self.traininputtensor = torch.tensor(data, dtype=torch.float)\n",
    "        self.output = torch.tensor(annotation, dtype=torch.float)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_image = self.traininputtensor[index].unsqueeze(0)  # Добавляет измерение канала, становится (1, depth, height, width)\n",
    "        output_label = self.output[index].unsqueeze(0)  # То же самое для метки\n",
    "        return input_image, output_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.traininputtensor.size(dim=0)\n",
    "\n",
    "\n",
    "class DataTest(Dataset):\n",
    "\n",
    "    def __init__(self, data, annotation):\n",
    "        self.testinputtensor = torch.tensor(data, dtype=torch.float)\n",
    "        self.output = torch.tensor(annotation, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_image = self.testinputtensor[index].unsqueeze(0)  # Добавляет измерение канала, становится (1, depth, height, width)\n",
    "        output_label = self.output[index].unsqueeze(0)  # То же самое для метки\n",
    "        return input_image, output_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.testinputtensor.size(dim=0)\n",
    "\n",
    "\n",
    "def changezax(data, z):\n",
    "    while len(data) < z:\n",
    "        data.append(np.zeros((96, 96), dtype=np.uint8))\n",
    "    data = data[:z]\n",
    "    return data\n",
    "\n",
    "\n",
    "def splitToTest1(annot, data, test=3):\n",
    "    k = test\n",
    "    traindata = data.copy()\n",
    "    trainannot = annot.copy()\n",
    "    testdata = []\n",
    "    testannot = []\n",
    "    testdatafinal = []\n",
    "    testannotfinal = []\n",
    "    trainannotfinal = []\n",
    "    traindatafinal = []\n",
    "    while k!=0:\n",
    "        rand = randint(0, len(traindata)-1)\n",
    "        testdata.append(traindata[rand])\n",
    "        testannot.append(trainannot[rand])\n",
    "        traindata.pop(rand - 1)\n",
    "        trainannot.pop(rand - 1)\n",
    "        k -= 1\n",
    "    for i in range(len(testdata)):\n",
    "        testdatafinal.append(np.array(testdata[i]))\n",
    "        print(np.array(testdata[i]).shape)\n",
    "        testannotfinal.append(np.array(testannot[i]))\n",
    "    for k in range(len(traindata)):\n",
    "        traindatafinal.append(np.array(traindata[k]))\n",
    "        trainannotfinal.append(np.array(trainannot[k]))\n",
    "    \n",
    "    return[testdatafinal, testannotfinal, traindatafinal, trainannotfinal]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def splitToTest(annot, data, test=3):\n",
    "    k = test\n",
    "    traindata = data.copy()\n",
    "    trainannot = annot.copy()\n",
    "    testdata = []\n",
    "    testannot = []\n",
    "    data1 = []\n",
    "    dat = []\n",
    "    while k!=0:\n",
    "        rand = randint(0, len(traindata))\n",
    "        testdata.append(traindata[rand - 1])\n",
    "        testannot.append(trainannot[rand - 1])\n",
    "        traindata.pop(rand - 1)\n",
    "        trainannot.pop(rand - 1)\n",
    "        k -= 1\n",
    "    for i in range(len(traindata)):\n",
    "        data1.append({\"image\": torch.tensor((traindata[i])), \"label\": torch.tensor(trainannot[i])})\n",
    "    for k in range(len(testdata)):\n",
    "        dat.append({\"image\": torch.tensor(testdata[k]), \"label\": torch.tensor(testannot[k])})\n",
    "    return[data1, dat]\n",
    "\n",
    "\n",
    "def preperingdata(path_to_masks, path_to_img, z):\n",
    "    labels = []\n",
    "    data = []\n",
    "    for floader in path_to_masks.iterdir():\n",
    "            print(\"Floader\", floader)\n",
    "            annot = []\n",
    "            for file in floader.iterdir():\n",
    "                img = Image.open(file)\n",
    "                if img.mode != \"L\":\n",
    "                    img = img.convert(\"L\")\n",
    "                img = img.resize((96, 96))\n",
    "                img_array = np.array(img)\n",
    "                annot.append(img_array)\n",
    "            #print(np.array(changezax(annot, z=z)).shape)\n",
    "            labels.append(changezax(annot, z=z))\n",
    "    for floader1 in path_to_img.iterdir():\n",
    "        for floader2 in floader1.iterdir():\n",
    "            if floader2.is_dir():\n",
    "                pic = []\n",
    "                print(\"Floader\", floader2)\n",
    "                for picture in floader2.iterdir():\n",
    "                    imga = Image.open(picture)\n",
    "                    if imga.mode != \"L\":\n",
    "                        imga = imga.convert(\"L\")\n",
    "                    imga = imga.resize((96, 96))\n",
    "                    array = np.array(imga)\n",
    "                    pic.append(array)\n",
    "                data.append(changezax(pic, z=z))\n",
    "                #print(np.array(pic).shape)\n",
    "    return [data, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\1\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\10\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\11\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\12\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\13\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\14\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\15\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\16\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\17\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\18\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\19\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\2\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\20\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\3\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\4\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\5\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\6\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\7\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\8\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks\\9\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\1\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\10\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\11\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\12\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\13\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\14\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\15\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\16\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\17\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\18\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\19\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\2\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\20\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\3\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\4\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\5\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\6\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\7\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\8\\data\n",
      "Floader C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase\\9\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.unetr UNETR.__init__:pos_embed: Argument `pos_embed` has been deprecated since version 1.2. It will be removed in version 1.4. please use `proj_type` instead.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "directory_path = Path(r'C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\workspase')\n",
    "mask_path = Path(r'C:\\Users\\User\\Desktop\\pilsen_pigs_2023_cvat_backup\\masks')\n",
    "data = preperingdata(mask_path, directory_path, z=96)\n",
    "\n",
    "\n",
    "data1 = splitToTest(data=data[0], annot=data[1])\n",
    "\n",
    "\n",
    "# train_ds = CacheDataset(\n",
    "#     data=data1[0],\n",
    "#     cache_num=24,\n",
    "#     cache_rate=1.0,\n",
    "#     num_workers=8,\n",
    "# )\n",
    "train_loader = DataLoader(data1[0], batch_size=1, shuffle=True, num_workers=8, pin_memory=True)\n",
    "# val_ds = CacheDataset(\n",
    "#     data=data1[1], \n",
    "#     cache_num=6, \n",
    "#     cache_rate=1.0, \n",
    "#     num_workers=4\n",
    "# )\n",
    "val_loader = DataLoader(data1[1], batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "num_epochs = 20\n",
    "rate_learning = 1e-4\n",
    "device = get_default_device()\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "modelwise = UNETR(   #just_to_copy_weights\n",
    "    in_channels=1,\n",
    "    out_channels=14,\n",
    "    img_size=(96, 96, 96),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    pos_embed=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "modelwise.load_state_dict(torch.load(os.path.join(r\"D:\\UNETR\", \"best_metric_model.pth\")))\n",
    "model_state_dict1 = modelwise.state_dict()\n",
    "for name_dst, param_dst in model.named_parameters():\n",
    "    if name_dst in modelwise.state_dict():\n",
    "        param_src = model.state_dict()[name_dst]\n",
    "        if param_src.size() == param_dst.size():\n",
    "            param_dst.data.copy_(param_src.data)\n",
    "        else:\n",
    "            print(f\"Skipping layer {name_dst} due to size mismatch\")\n",
    "        \n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-175,\n",
    "            a_max=250,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 2.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Score: 0.5001701712608337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dice_coefficient_3d(y_true, y_pred, smooth=1.0):\n",
    "    # Плоское представление массивов\n",
    "    y_true_f = y_true.contiguous().view(-1)\n",
    "    y_pred_f = y_pred.contiguous().view(-1)\n",
    "    # Вычисление пересечения\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    # Расчёт Dice Coefficient\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "# Предположим, у вас есть 3D маски\n",
    "y_true = torch.rand(size=(1, 1, 10, 256, 256))  # Истинная маска\n",
    "y_pred = torch.rand(size=(1, 1, 10, 256, 256))  # Предсказанная маска\n",
    "\n",
    "# Binarize predictions and ground truth for example\n",
    "y_true = (y_true > 0.5).float()\n",
    "y_pred = (y_pred > 0.5).float()\n",
    "\n",
    "dice_score = dice_coefficient_3d(y_true, y_pred)\n",
    "print(f\"Dice Score: {dice_score}\")\n",
    "\n",
    "#output = model(t)\n",
    "#print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "            val_outputs = sliding_window_inference(val_inputs, (512 ,512, 784), 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))  # noqa: B038\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val\n",
    "\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].cuda(), batch[\"label\"].cuda())\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(  # noqa: B038\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)\n",
    "        )\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True)\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(r\"D:\\result\", \"best_metric_model.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m metric_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m global_step \u001b[38;5;241m<\u001b[39m max_iterations:\n\u001b[1;32m---> 12\u001b[0m     global_step, dice_val_best, global_step_best \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m(global_step, train_loader, dice_val_best, global_step_best)\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_metric_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "max_iterations = 100\n",
    "eval_num = 500\n",
    "post_label = AsDiscrete(to_onehot=1)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=1)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(global_step, train_loader, dice_val_best, global_step_best)\n",
    "model.load_state_dict(torch.load(os.path.join(r\"D:\\result\", \"best_metric_model.pth\")))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Iteration Average Loss\")\n",
    "x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 96)\n",
      "(96, 96, 96)\n",
      "(96, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/17 [00:00<?, ?batch/s]C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\monai\\losses\\dice.py:146: UserWarning: single channel prediction, `softmax=True` ignored.\n",
      "  warnings.warn(\"single channel prediction, `softmax=True` ignored.\")\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\monai\\losses\\dice.py:155: UserWarning: single channel prediction, `to_onehot_y=True` ignored.\n",
      "  warnings.warn(\"single channel prediction, `to_onehot_y=True` ignored.\")\n",
      "Epoch 1/2: 100%|██████████| 17/17 [00:26<00:00,  1.54s/batch]\n",
      "Epoch 2/2: 100%|██████████| 17/17 [00:25<00:00,  1.50s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train history [28.71602153778076, 24.142449975013733]\n",
      "Accuracy train [tensor(4.8443e-05, device='cuda:0'), tensor(0.1364, device='cuda:0'), tensor(4.9995e-05, device='cuda:0'), tensor(3.1705e-05, device='cuda:0'), tensor(3.1823e-05, device='cuda:0'), tensor(3.6761e-05, device='cuda:0'), tensor(2.1911e-05, device='cuda:0'), tensor(2.0425e-05, device='cuda:0'), tensor(3.3533e-05, device='cuda:0'), tensor(2.0422e-05, device='cuda:0'), tensor(1.8949e-05, device='cuda:0'), tensor(2.8228e-05, device='cuda:0'), tensor(2.2847e-05, device='cuda:0'), tensor(1.8499e-05, device='cuda:0'), tensor(2.2329e-05, device='cuda:0'), tensor(2.1232e-05, device='cuda:0'), tensor(1.7821e-05, device='cuda:0'), tensor(1.7279e-05, device='cuda:0'), tensor(2.8773e-05, device='cuda:0'), tensor(1.8002e-05, device='cuda:0'), tensor(1.9257e-05, device='cuda:0'), tensor(2.0964e-05, device='cuda:0'), tensor(2.3679e-05, device='cuda:0'), tensor(3.2853e-05, device='cuda:0'), tensor(0.2716, device='cuda:0'), tensor(3.2099e-05, device='cuda:0'), tensor(2.3367e-05, device='cuda:0'), tensor(1.7331e-05, device='cuda:0'), tensor(1.7219e-05, device='cuda:0'), tensor(2.5178e-05, device='cuda:0'), tensor(1.9633e-05, device='cuda:0'), tensor(1.8202e-05, device='cuda:0'), tensor(1.5011e-05, device='cuda:0'), tensor(1.4983e-05, device='cuda:0')]\n",
      "Accuracy validation [tensor(1.4886e-05, device='cuda:0'), tensor(1.5973e-05, device='cuda:0'), tensor(2.3676e-05, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "def dice_coefficient_3d(y_true, y_pred, smooth=1.0):\n",
    "    # Плоское представление массивов\n",
    "    y_true_f = y_true.contiguous().view(-1)\n",
    "    y_pred_f = y_pred.contiguous().view(-1)\n",
    "    # Вычисление пересечения\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    # Расчёт Dice Coefficient\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data2 = splitToTest1(data=data[0], annot=data[1])\n",
    "train = DataTrain(data2[2], data2[3])\n",
    "test = DataTest(data2[0], data2[1])\n",
    "dataloader_train = DataLoader(dataset=train, batch_size=1, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset=test, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss_fn =  DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "lr = 1e-4\n",
    "num_epochs = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimazer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "cm = ConfusionMatrix(num_classes=2)\n",
    "dice = DiceCoefficient(cm)\n",
    "history = []\n",
    "history1 = []\n",
    "acc_val = []\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "for epochs in range(num_epochs):\n",
    "    with tqdm(total=17, desc=f'Epoch {epochs + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "        running_loss = 0\n",
    "        val_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimazer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            loss.backward()\n",
    "            optimazer.step()\n",
    "            running_loss += loss.item()\n",
    "            preds = (labels>0.5).float()\n",
    "            output = (output>0.5).float()\n",
    "            acc_train.append(dice_coefficient_3d(preds, output))\n",
    "            pbar.update(1)\n",
    "        history.append(running_loss)\n",
    "correct = 0\n",
    "total = 0\n",
    "for j, data in enumerate(dataloader_test):\n",
    "    with torch.no_grad():\n",
    "        inputs_for_test, labels_for_test = data\n",
    "        inputs_for_test = inputs_for_test.to(device)\n",
    "        labels_for_test = labels_for_test.to(device)\n",
    "        output_for_test = model(inputs_for_test)\n",
    "        preds = (labels_for_test>0.5).float()\n",
    "        output = (output_for_test>0.5).float()\n",
    "        acc_val.append(dice_coefficient_3d(preds, output))\n",
    "print(\"Train history\", history)\n",
    "#print(\"Validation hisoty\", history1)\n",
    "print(\"Accuracy train\", acc_train)\n",
    "print(\"Accuracy validation\", acc_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
